{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d8158dfddb2ac72",
   "metadata": {},
   "source": [
    "# Assignment 3\n",
    "\n",
    "In this assignment, you will refactor the code from the lecture by...\n",
    "1. Adding a train-validation split.\n",
    "2. Using `nn.Module` for defining the model.\n",
    "3. Implementing the training loop."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e74cf4f768c1edcc",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "project_path = \"C:\\\\Users\\\\eunse\\\\OneDrive\\\\바탕 화면\\\\LLM101n\"\n",
    "sys.path.insert(0, project_path)\n",
    "import matplotlib.pyplot as plt\n",
    "from dataclasses import dataclass\n",
    "from typing import Tuple\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from utils import load_text, set_seed, configure_device\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb2cbcb0169f77d",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8bfe28c1af6b7",
   "metadata": {},
   "source": [
    "**Note:** If you do not have a GPU, decrease the `max_steps`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f87ea90a462f04bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class MLPConfig:\n",
    "    root_dir: str = os.getcwd() + \"/../../\"\n",
    "    dataset_path: str = \"data/names.txt\"\n",
    "    device: torch.device = torch.device('cpu')  # Automatic device configuration\n",
    "\n",
    "    # Tokenizer\n",
    "    vocab_size: int = 0  # Set later\n",
    "    \n",
    "    # Model\n",
    "    context_size: int = 3\n",
    "    d_embed: int = 16\n",
    "    d_hidden: int = 64\n",
    "    \n",
    "    # Training\n",
    "    val_size: float = 0.1\n",
    "    batch_size: int = 32\n",
    "    max_steps: int = 10000\n",
    "    lr: float = 2e-3\n",
    "    val_interval: int = 1000\n",
    "\n",
    "    seed: int = 101\n",
    "    \n",
    "config = MLPConfig()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21388a355d7684a2",
   "metadata": {},
   "source": [
    "## Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c978c462c20bd1aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed set to 101\n"
     ]
    }
   ],
   "source": [
    "set_seed(config.seed)\n",
    "generator = torch.Generator().manual_seed(config.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de6979c114cc847",
   "metadata": {},
   "source": [
    "## Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9ca76989a82c131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on cpu\n"
     ]
    }
   ],
   "source": [
    "config.device = configure_device()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd06cd53a8099029",
   "metadata": {},
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ec4919298103e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = [chr(i) for i in range(97, 123)]  # all alphabet characters\n",
    "chars.insert(0, \".\")  # Add special token\n",
    "config.vocab_size = len(chars)\n",
    "str2idx = {char: idx for idx, char in enumerate(chars)}\n",
    "idx2str = {idx: char for char, idx in str2idx.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "143169f16782a55f",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8acd205ab399fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded text data from c:\\Users\\eunse\\Documents\\LLM101n\\notebooks\\Assignments/../../data/names.txt (length: 228145 characters).\n"
     ]
    }
   ],
   "source": [
    "names = load_text(config.root_dir + config.dataset_path).splitlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908b723455adc6b5",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ce74000c6911e0",
   "metadata": {},
   "source": [
    "### Task 1: Train-Validation split\n",
    "\n",
    "Using all the data for training leads to overfitting.\n",
    "\n",
    "Implement a function to split the text into training and validation sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7d442ad0a2d2a836",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_names(_names: str, val_size: float) -> Tuple[str, str]:\n",
    "    \"\"\"\n",
    "    Split text into training and validation sets.\n",
    "\n",
    "    Args:\n",
    "        _names (str): The data to split.\n",
    "        val_size (float): Size of the validation set.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[str, str]: Training and validation data.\n",
    "    \"\"\"\n",
    "    if val_size <= 0 or val_size >= 1:\n",
    "        raise ValueError(f\"Invalid validation size: {val_size}\")\n",
    "    ################################################################################\n",
    "    # TODO:                                                                        #\n",
    "    # Split the data into training and validation sets.                            #\n",
    "    ################################################################################\n",
    "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "    from random import shuffle\n",
    "    names_copy = _names.copy()\n",
    "    shuffle(names_copy)\n",
    "\n",
    "    split_idx = int(len(names_copy) * (1 - val_size))\n",
    "    train_text = names_copy[:split_idx]\n",
    "    val_text = names_copy[split_idx:]\n",
    "\n",
    "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    return train_text, val_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fd12c70f91c99915",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 28829\n",
      "Validation set size: 3204\n"
     ]
    }
   ],
   "source": [
    "train_names, val_names = split_names(names, config.val_size)\n",
    "print(f\"Training set size: {len(train_names)}\")\n",
    "print(f\"Validation set size: {len(val_names)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6d20c3c432239094",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(_names):\n",
    "    inputs, targets = [], []\n",
    "\n",
    "    for name in _names:\n",
    "        context = [0] * config.context_size\n",
    "        \n",
    "        for char in name + \".\":\n",
    "            idx = str2idx[char]\n",
    "            inputs.append(context)\n",
    "            targets.append(idx)\n",
    "            context = context[1:] + [idx]  # Shift the context by 1 character\n",
    "\n",
    "    inputs = torch.tensor(inputs)\n",
    "    targets = torch.tensor(targets)\n",
    "    \n",
    "    return inputs, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "753ed8355d96dd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs, train_targets = prepare_dataset(train_names)\n",
    "val_inputs, val_targets = prepare_dataset(val_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3afb919d68490621",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b30b401056e9d88",
   "metadata": {},
   "source": [
    "### Task 2: `nn.Module`.\n",
    "\n",
    "PyTorch provides a module called `nn.Module` for defining models. Instead of defining every layer as a separate tensor, we can wrap it all up in a class. This provides better organization and encapsulation.\n",
    "\n",
    "[PyTorch Documentation](https://pytorch.org/docs/stable/generated/torch.nn.Module.html)\n",
    "\n",
    "Implement a class `MLP` that inherits from `nn.Module`.\n",
    "(Hint: You can use `nn.Embedding` and `nn.Linear`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a56fae6095a01da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    ################################################################################\n",
    "    # TODO:                                                                        #\n",
    "    # Define the __init__ and forward methods for the MLP model.                   #\n",
    "    ################################################################################\n",
    "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "    def __init__(self, vocab_size, context_size, d_embed, d_hidden):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, d_embed)\n",
    "        self.fc1 = nn.Linear(context_size * d_embed, d_hidden)\n",
    "        self.fc2 = nn.Linear(d_hidden, vocab_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)        # [B, C] -> [B, C, d_embed]\n",
    "        x = x.view(x.shape[0], -1)   # Flatten: [B, C*d_embed]\n",
    "        x = F.relu(self.fc1(x))\n",
    "        logits = self.fc2(x)\n",
    "        return logits\n",
    "\n",
    "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    # Note: do not include softmax in the forward pass since it is already included in the loss function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1145b4db700ccaf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (embedding): Embedding(27, 16)\n",
      "  (fc1): Linear(in_features=48, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=27, bias=True)\n",
      ")\n",
      "Number of parameters: 5323\n",
      "Input shape: torch.Size([2, 3])\n",
      "Output shape: torch.Size([2, 27])\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "mlp = MLP(config.vocab_size, config.context_size, config.d_embed, config.d_hidden)\n",
    "mlp.to(config.device) # Move the model to the device\n",
    "print(mlp)\n",
    "print(\"Number of parameters:\", sum(p.numel() for p in mlp.parameters()))\n",
    "\n",
    "# Example forward pass\n",
    "example_input = train_inputs[:2]\n",
    "example_input = example_input.to(config.device)  # Move the data to the device\n",
    "print(f\"Input shape: {example_input.shape}\")\n",
    "print(f\"Output shape: {mlp(example_input).shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424042449c0aa770",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b460fa44e187b3",
   "metadata": {},
   "source": [
    "### Task 3: Training loop.\n",
    "\n",
    "Implement the training loop for the model.\n",
    "\n",
    "What is an optimizer? [PyTorch Documentation](https://pytorch.org/docs/stable/optim.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "34c5737ae1ca96d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model):\n",
    "    steps = []\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    \n",
    "    # Define the optimizer\n",
    "    ################################################################################\n",
    "    # TODO:                                                                        #\n",
    "    # Define the optimizer for the model.                                          #\n",
    "    # Use stochastic gradient descent (SGD) with the learning rate from the config.#\n",
    "    ################################################################################\n",
    "    # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=config.lr)\n",
    "\n",
    "    # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "    \n",
    "    for step in range(1, config.max_steps + 1):\n",
    "        # Training\n",
    "        # Sample batch\n",
    "        idx = torch.randperm(len(train_inputs))[:config.batch_size]\n",
    "        x, y = train_inputs[idx], train_targets[idx]\n",
    "        x, y = x.to(config.device), y.to(config.device)  # Move the data to the device\n",
    "        \n",
    "        ################################################################################\n",
    "        # TODO:                                                                        #\n",
    "        # Implement the forward pass and the backward pass                             #\n",
    "        ################################################################################\n",
    "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(x)\n",
    "        loss = F.cross_entropy(logits, y)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "        \n",
    "        # Validation\n",
    "        if step % config.val_interval == 0:\n",
    "            # Validation loss\n",
    "            with torch.no_grad():\n",
    "                val_logits = model(val_inputs.to(config.device))\n",
    "                val_loss = F.cross_entropy(val_logits, val_targets.to(config.device)).item()\n",
    "                val_losses.append(val_loss)\n",
    "            \n",
    "        # Logging\n",
    "        steps.append(step)\n",
    "        train_losses.append(loss.item())\n",
    "        if step % config.val_interval == 0:\n",
    "            print(f\"Step {step}: Train Loss = {loss.item():.4f}, Val Loss = {val_loss:.4f}\")\n",
    "\n",
    "    # Plot the loss\n",
    "    plt.figure()\n",
    "    plt.plot(steps, train_losses, label=\"Train\")\n",
    "    plt.plot(steps[::config.val_interval], val_losses, label=\"Validation\")\n",
    "    plt.xlabel(\"Steps\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "88b77b52fc6bd791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1000: Train Loss = 3.0727, Val Loss = 2.9438\n",
      "Step 2000: Train Loss = 2.8507, Val Loss = 2.7899\n",
      "Step 3000: Train Loss = 2.7482, Val Loss = 2.7088\n",
      "Step 4000: Train Loss = 2.9084, Val Loss = 2.6582\n",
      "Step 5000: Train Loss = 2.7268, Val Loss = 2.6201\n",
      "Step 6000: Train Loss = 2.4601, Val Loss = 2.5914\n",
      "Step 7000: Train Loss = 2.7775, Val Loss = 2.5674\n",
      "Step 8000: Train Loss = 2.5537, Val Loss = 2.5479\n",
      "Step 9000: Train Loss = 2.2593, Val Loss = 2.5311\n",
      "Step 10000: Train Loss = 2.7676, Val Loss = 2.5159\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "train(mlp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2880695e69f27e",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254cfa9b9167cecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_name():\n",
    "    new_name = []\n",
    "    context = [0] * config.context_size\n",
    "    \n",
    "    while True:\n",
    "        # forward pass\n",
    "        x = torch.tensor(context).unsqueeze(0).to(config.device)\n",
    "        logits = mlp(x)\n",
    "        \n",
    "        # sample\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "        idx = torch.multinomial(probs, num_samples=1).item()\n",
    "        \n",
    "        # update context\n",
    "        new_name.append(idx2str[idx])\n",
    "        context = context[1:] + [idx]\n",
    "        \n",
    "        # break if \".\"\n",
    "        if idx == 0:\n",
    "            break\n",
    "        \n",
    "    return \"\".join(new_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18536bfec99f36ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(5):\n",
    "    print(generate_name())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5672f33432bc5671",
   "metadata": {},
   "source": [
    "## Extra Credit\n",
    "\n",
    "Change the model configuration and hyperparameters to achieve the following:\n",
    "\n",
    "Generate good-looking names and get the lowest **validation loss** as possible.\n",
    "\n",
    "Rules:\n",
    "- Do not change the random seed.\n",
    "- Do not change the validation set size.\n",
    "- External data is not allowed."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
